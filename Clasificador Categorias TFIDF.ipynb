{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPbF2OtHwePH"
   },
   "source": [
    "# Clasificacion de Categorias usando TF-IDF\n",
    "\n",
    "Autor: Remberto López"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXZ6DIBLwus3"
   },
   "source": [
    "# Problema\n",
    "\n",
    "Se busca clasificar automáticamente textos en tres categorías diferentes: deportivos, políticos y de entretenimiento. Se tiene un corpus de textos divididos en estas tres categorías para entrenar el modelo. Se desarrollará un sistema de clasificación que pueda determinar a qué categoría pertenece un nuevo texto de consulta.\n",
    "\n",
    "El corpus de entrenamiento consta de una colección de textos deportivos, políticos y de entretenimiento. Cada texto está representado como un documento, y se tiene una lista de estos documentos junto con sus etiquetas de categoría correspondientes.\n",
    "\n",
    "Se utilizará la técnica de codificación TF-IDF (Term Frequency-Inverse Document Frequency) para convertir los documentos de texto en vectores numéricos, lo que nos permitirá cuantificar la importancia relativa de cada palabra en cada documento. Luego, se calculará la similitud del coseno entre el texto de consulta  (query) y cada una de las categorías para determinar que categoría es más probable a la que pertenezca.\n",
    "\n",
    "Los objetivos son:\n",
    "\n",
    "1. Preprocesamiento de los textos: carga de textos, limpieza de texto y eliminación de stop words.\n",
    "2. Crear un modelo de codificación TF-IDF.\n",
    "3. Implementar la similitud del coseno entre el texto de consulta y cada categoría.\n",
    "4. Desarrollar una función de clasificación que tome un texto de consulta como entrada y devuelva la categoría más probable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "patxEghU624s"
   },
   "source": [
    "# 1. Procesamiento de datos\n",
    "\n",
    "## 1.1 Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5gFYXR17K3U"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import os\n",
    "\n",
    "PATH = \"corpus/\"\n",
    "contenido = glob.glob(PATH+\"*.txt\")\n",
    "diccionario_corpus = {}\n",
    "for textos in contenido:\n",
    "  with open(textos,\"r\") as textos_txt:\n",
    "    corpus = textos_txt.read()\n",
    "  categoria = os.path.basename(textos)[:-6]\n",
    "  if categoria in diccionario_corpus.keys():\n",
    "    diccionario_corpus[categoria].append(corpus)\n",
    "  else:\n",
    "    diccionario_corpus[categoria] = [corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ILeVDaK8VK0",
    "outputId": "c300eff0-7836-4474-9278-7ce3ab3da955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte : ['El equipo de fútbol local logró una emocionante victoria en las semifinales del campeonato regional anoche. Con un gol en el tiempo de descuento, aseguraron su lugar en la final contra su rival histórico. Los aficionados están eufóricos y se espera un lleno total en el estadio para el enfrentamiento decisivo el próximo fin de semana.\\n\\n\\n', 'La estrella del tenis, que ha dominado las canchas durante la última década, sorprendió al mundo del deporte al anunciar su retiro del circuito profesional. Con múltiples títulos de Grand Slam y una carrera brillante, deja un legado imborrable en el tenis mundial. Los fanáticos lamentan su partida, pero celebran sus innumerables logros y momentos inolvidables en el deporte.\\n\\n\\n', 'El equipo de baloncesto de la NBA ha cerrado un acuerdo histórico al firmar a una joven promesa del deporte por un contrato millonario. Con habilidades excepcionales y un potencial ilimitado, esta nueva adquisición promete llevar al equipo a nuevas alturas en la próxima temporada. Los aficionados están emocionados por el futuro del equipo con esta incorporación.\\n\\n', 'El campeón defensor de la carrera ciclista más prestigiosa del mundo anunció su retiro de la competencia debido a una lesión sufrida durante una etapa crucial. A pesar de los esfuerzos del equipo médico, la gravedad de la lesión lo obliga a abandonar la carrera. Los seguidores del ciclismo lamentan la noticia y desean una pronta recuperación al ciclista.\\n']\n",
      "politica : ['El principal partido de oposición ha anunciado una campaña de reforma electoral para abordar preocupaciones sobre la transparencia y la equidad en el proceso electoral. Entre las propuestas se incluyen cambios en la financiación de campañas, la implementación de medidas de seguridad cibernética y la garantía de la independencia de las autoridades electorales. El movimiento ha generado un debate nacional sobre el futuro de la democracia y la integridad del sistema electoral.\\n', 'El debate legislativo se intensifica mientras los partidos políticos luchan con diferencias irreconciliables sobre un proyecto de ley crucial. Las negociaciones han llegado a un punto muerto debido a las posturas inflexibles de ambas partes, lo que plantea dudas sobre la posibilidad de llegar a un acuerdo en el corto plazo. Los ciudadanos esperan con impaciencia una resolución, mientras los líderes políticos buscan soluciones para superar el estancamiento.\\n\\n', 'El gobierno emitió una advertencia sobre posibles conflictos fronterizos después de un aumento en la escalada de tensiones con un país vecino. Las disputas territoriales han aumentado las preocupaciones sobre la posibilidad de un enfrentamiento armado, lo que ha llevado a un llamado urgente a la diplomacia y a la intervención de mediadores internacionales para evitar una crisis.\\n\\n', 'Un escándalo de corrupción ha sacudido al gobierno después de que se revelara una investigación sobre presuntas malversaciones de fondos por parte de varios funcionarios de alto rango. Las acusaciones incluyen sobornos, nepotismo y manipulación de contratos gubernamentales. La indignación pública está en aumento y se exige una investigación exhaustiva para llevar a los responsables ante la justicia y restaurar la confianza en las instituciones.\\n\\n', 'El recién elegido presidente anunció su compromiso de implementar cambios significativos en las políticas económicas del país. Durante su discurso de aceptación, prometió medidas audaces para abordar el desempleo, mejorar el acceso a la atención médica y revitalizar la economía. Sus propuestas han generado un intenso debate entre los expertos y los ciudadanos, mientras el país espera con expectación los primeros pasos de su administración.\\n\\n\\n']\n",
      "entretenimiento : ['La anticipación llegó a su punto máximo cuando la película de acción más esperada del año finalmente hizo su debut en la gran pantalla. Con una trama llena de intriga, emocionantes escenas de acción y efectos visuales impresionantes, la película ha cautivado a audiencias de todas las edades. Los críticos elogian las actuaciones estelares y la dirección magistral, mientras que los fanáticos ya esperan ansiosamente la próxima entrega de la franquicia.\\n\\n', 'La estrella del pop mundialmente reconocida sorprendió a sus seguidores al revelar detalles emocionantes sobre su próximo álbum. En una entrevista exclusiva, compartió la inspiración detrás de las nuevas canciones, así como colaboraciones sorpresa con artistas de renombre. Con una mezcla de ritmos pegajosos y letras profundas, el álbum promete ser un éxito instantáneo y consolidar aún más su posición en la cima de la industria musical.\\n', 'El prestigioso festival de cine internacional abrió sus puertas para su edición anual, ofreciendo una selección ecléctica de películas de vanguardia de todo el mundo. Desde dramas conmovedores hasta comedias ingeniosas y documentales provocativos, el festival celebra la diversidad y la creatividad en el cine contemporáneo. Con proyecciones especiales, paneles de discusión y eventos exclusivos, el festival promete ser una experiencia inolvidable para cinéfilos y profesionales de la industria por igual.\\n']\n"
     ]
    }
   ],
   "source": [
    "for categoria,corpus in diccionario_corpus.items(): #Usamos este metodo .items() para iterar segun categorias y sus respectivos corpus para ver si todo esta bien guardado\n",
    "  print(f\"{categoria} : {corpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7sexLgy80pX"
   },
   "source": [
    "## 1.2 Limpieza de texto\n",
    "### 1.2.1 Limpieza de simbolos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0ceCylH8yOR"
   },
   "outputs": [],
   "source": [
    "def limpieza_simbolos(values, simbolos):\n",
    "    \"\"\"\n",
    "    Elimina un conjunto de símbolos de una lista de textos y convierte el texto resultante a minúsculas.\n",
    "\n",
    "    Args:\n",
    "        values (list of str): Lista de textos en los cuales se eliminarán los símbolos.\n",
    "        simbolos (list of str): Lista de símbolos que se deben eliminar de los textos.\n",
    "\n",
    "    Returns:\n",
    "        list of str: Lista de textos procesados, sin los símbolos indicados y en minúsculas.\n",
    "    \"\"\"\n",
    "    lista_values_limpios = []\n",
    "    for corpus in values:\n",
    "        texto = corpus\n",
    "        for simbolo in simbolos:\n",
    "            texto = texto.replace(simbolo, \"\")\n",
    "        lista_values_limpios.append(texto.lower())  # Aprovechamos de dejar todo en minúsculas con .lower()\n",
    "    return lista_values_limpios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKX8vsR389kV"
   },
   "outputs": [],
   "source": [
    "simbolos_redundantes = [ \".\",\n",
    "    \",\",  # Comas\n",
    "    \";\",  # Puntos y comas\n",
    "    \"()\", \"[]\", \"{}\",  # Paréntesis redundantes\n",
    "    \"'\", '\"',  # Comillas redundantes\n",
    "    \"  \", \"\\t\", \"\\n\",  # Espacios en blanco excesivos\n",
    "    \"+\", \"-\", \"*\", \"/\",  # Operadores redundantes\n",
    "]\n",
    "for categoria, values in diccionario_corpus.items(): #iteramos en funcion de la categoria y sus respectivos valores\n",
    "  diccionario_corpus[categoria] = limpieza_simbolos(values,simbolos_redundantes) # el texto de los values(corpus) se modifican y se agregan directamente en su respectiva categoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtjZvS_W-Mnq"
   },
   "source": [
    "## 1.2.2 Limpieza de Stop-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faA76IOJ-PpU"
   },
   "outputs": [],
   "source": [
    "def limpieza_stop_words(values, stop_words):\n",
    "    \"\"\"\n",
    "    Elimina las stop words de una lista de textos.\n",
    "\n",
    "    Args:\n",
    "        values (list of str): Lista de textos que se desea procesar.\n",
    "        stop_words (list of str): Lista de palabras consideradas stop words que se deben eliminar de los textos.\n",
    "\n",
    "    Returns:\n",
    "        list of str: Lista de textos procesados, sin las stop words.\n",
    "    \"\"\"\n",
    "    lista_values_limpios = []  # Se inicializa una lista vacía para almacenar los textos después de limpiar las stop words.\n",
    "    for corpus in values:  # Iteramos sobre cada texto en la lista de valores de entrada.\n",
    "        texto = corpus  # Tomamos el texto actual para procesar.\n",
    "        palabras = texto.split()  # Dividimos el texto en palabras individuales.\n",
    "        palabras_filtradas = [palabra for palabra in palabras if palabra not in stop_words]  # Filtramos las palabras eliminando las que se encuentren en la lista de stop words.\n",
    "        texto_filtrado = \" \".join(palabras_filtradas)  # Unimos las palabras filtradas de vuelta en un solo texto.\n",
    "        lista_values_limpios.append(texto_filtrado)  # Añadimos el texto filtrado a la lista de textos limpios.\n",
    "\n",
    "    return lista_values_limpios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnZzzwTv-R89"
   },
   "outputs": [],
   "source": [
    "# Palabras redudantes en español\n",
    "stop_words_espanol = [\n",
    "    \"a\", \"al\", \"algo\", \"algunas\", \"algunos\", \"ante\", \"antes\",\n",
    "    \"como\", \"con\", \"contra\", \"cual\", \"cuando\", \"de\", \"del\",\n",
    "    \"desde\", \"donde\", \"durante\", \"e\", \"el\", \"ella\", \"ellas\",\n",
    "    \"ellos\", \"en\", \"entre\", \"era\", \"erais\", \"eran\", \"eras\",\n",
    "    \"eres\", \"es\", \"esa\", \"esas\", \"ese\", \"eso\", \"esos\", \"esta\",\n",
    "    \"estaba\", \"estabais\", \"estaban\", \"estabas\", \"estad\", \"estada\",\n",
    "    \"estadas\", \"estado\", \"estados\", \"estamos\", \"estando\", \"estar\",\n",
    "    \"estaremos\", \"estará\", \"estarán\", \"estarás\", \"estaré\", \"estaréis\",\n",
    "    \"estaría\", \"estaríais\", \"estaríamos\", \"estarían\", \"estarías\",\n",
    "    \"estas\", \"este\", \"estemos\", \"esto\", \"estos\", \"estoy\", \"estuve\",\n",
    "    \"estuviera\", \"estuvierais\", \"estuvieran\", \"estuvieras\", \"estuvieron\",\n",
    "    \"estuviese\", \"estuvieseis\", \"estuviesen\", \"estuvieses\", \"estuvimos\",\n",
    "    \"estuviste\", \"estuvisteis\", \"estuviéramos\", \"estuviésemos\", \"estuvo\",\n",
    "    \"está\", \"estábamos\", \"estáis\", \"están\", \"estás\", \"esté\", \"estéis\",\n",
    "    \"estén\", \"estés\", \"fue\", \"fuera\", \"fuerais\", \"fueran\", \"fueras\",\n",
    "    \"fueron\", \"fuese\", \"fueseis\", \"fuesen\", \"fueses\", \"fui\", \"fuimos\",\n",
    "    \"fuiste\", \"fuisteis\", \"fuéramos\", \"fuésemos\", \"ha\", \"habida\",\n",
    "    \"habidas\", \"habido\", \"habidos\", \"habiendo\", \"habremos\", \"habrá\",\n",
    "    \"habrán\", \"habrás\", \"habré\", \"habréis\", \"habría\", \"habríais\",\n",
    "    \"habríamos\", \"habrían\", \"habrías\", \"habéis\", \"había\", \"habíais\",\n",
    "    \"habíamos\", \"habían\", \"habías\", \"han\", \"has\", \"hasta\", \"hay\",\n",
    "    \"haya\", \"hayamos\", \"hayan\", \"hayas\", \"hayáis\", \"he\", \"hemos\",\n",
    "    \"hube\", \"hubiera\", \"hubierais\", \"hubieran\", \"hubieras\", \"hubieron\",\n",
    "    \"hubiese\", \"hubieseis\", \"hubiesen\", \"hubieses\", \"hubimos\", \"hubiste\",\n",
    "    \"hubisteis\", \"hubiéramos\", \"hubiésemos\", \"hubo\", \"la\", \"las\", \"le\",\n",
    "    \"les\", \"lo\", \"los\", \"me\", \"mi\", \"mis\", \"mucho\", \"muchos\", \"muy\",\n",
    "    \"más\", \"mí\", \"mía\", \"mías\", \"mío\", \"míos\", \"nada\", \"ni\", \"no\",\n",
    "    \"nos\", \"nosotras\", \"nosotros\", \"nuestra\", \"nuestras\", \"nuestro\",\n",
    "    \"nuestros\", \"o\", \"os\", \"otra\", \"otras\", \"otro\", \"otros\", \"para\",\n",
    "    \"pero\", \"poco\", \"por\", \"porque\", \"que\", \"quien\", \"quienes\", \"qué\",\n",
    "    \"se\", \"sea\", \"seamos\", \"sean\", \"seas\", \"sentid\", \"sentida\", \"sentidas\",\n",
    "    \"sentido\", \"sentidos\", \"seremos\", \"será\", \"serán\", \"serás\", \"seré\",\n",
    "    \"seréis\", \"sería\", \"seríais\", \"seríamos\", \"serían\", \"serías\", \"seáis\",\n",
    "    \"siente\", \"sin\", \"sintiendo\", \"sobre\", \"sois\", \"somos\", \"son\", \"soy\",\n",
    "    \"su\", \"sus\", \"suya\", \"suyas\", \"suyo\", \"suyos\", \"sí\", \"también\", \"tanto\",\n",
    "    \"te\", \"tendremos\", \"tendrá\", \"tendrán\", \"tendrás\", \"tendré\", \"tendréis\",\n",
    "    \"tendría\", \"tendríais\", \"tendríamos\", \"tendrían\", \"tendrías\", \"tened\",\n",
    "    \"tenemos\", \"tenga\", \"tengamos\", \"tengan\", \"tengas\", \"tengo\", \"tengáis\",\n",
    "    \"tenida\", \"tenidas\", \"tenido\", \"tenidos\", \"teniendo\", \"tenéis\", \"tenía\",\n",
    "    \"teníais\", \"teníamos\", \"tenían\", \"tenías\", \"ti\", \"tiene\", \"tienen\", \"toda\",\n",
    "    \"todas\", \"todo\", \"todos\", \"tu\", \"tus\", \"tuve\", \"tuviera\", \"tuvierais\",\n",
    "    \"tuvieran\", \"tuvieras\", \"tuvieron\", \"tuviese\", \"tuvieseis\", \"tuviesen\",\n",
    "    \"tuvieses\", \"tuvimos\", \"tuviste\", \"tuvisteis\", \"tuviéramos\", \"tuviésemos\",\n",
    "    \"tuvo\", \"tuya\", \"tuyas\", \"tuyo\", \"tuyos\", \"tú\", \"un\", \"una\", \"uno\", \"unos\",\n",
    "    \"vosotras\", \"vosotros\", \"vuestra\", \"vuestras\", \"vuestro\", \"vuestros\", \"y\",\n",
    "    \"ya\", \"yo\"\n",
    "]\n",
    "for categoria,values in diccionario_corpus.items(): #se usa misma lógica que en limpieza de simbolos, es decir, retorno del corpus ya limpio y que se cambia por el antiguo en su respectiva categoria\n",
    "  diccionario_corpus[categoria] = limpieza_stop_words(values, stop_words_espanol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fv0KKR0K_HWL"
   },
   "source": [
    "# 2. Codificación TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VzMEY-MACWqy"
   },
   "outputs": [],
   "source": [
    "def calculo_tf(texto, palabra_diccionario):\n",
    "    \"\"\"\n",
    "    Calcula la frecuencia de término (TF) de una palabra en un texto.\n",
    "\n",
    "    Args:\n",
    "        texto (str): Texto en el que se desea calcular la frecuencia de la palabra.\n",
    "        palabra_diccionario (str): Palabra cuya frecuencia se desea calcular en el texto.\n",
    "\n",
    "    Returns:\n",
    "        float: Frecuencia de término de la palabra en el texto, calculada como el número \n",
    "            de apariciones de la palabra dividido entre el total de palabras en el texto.\n",
    "    \"\"\"\n",
    "    # tf = repetición de la palabra en el documento / total de palabras del documento\n",
    "    total_palabras = len(texto.split())\n",
    "    repeticion_palabra = texto.count(palabra_diccionario)\n",
    "    tf = repeticion_palabra / total_palabras\n",
    "    return tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UAHkdIqhC_HG"
   },
   "outputs": [],
   "source": [
    "def calculo_idf(diccionario_corpus, palabra_diccionario):\n",
    "    \"\"\"\n",
    "    Calcula la frecuencia inversa de documentos (IDF) de una palabra en un corpus.\n",
    "\n",
    "    Args:\n",
    "        diccionario_corpus (dict): Diccionario donde las claves representan categorías y los valores \n",
    "            son listas de textos (documentos). Se usa para calcular cuántos documentos contienen la palabra.\n",
    "        palabra_diccionario (str): Palabra cuya IDF se desea calcular.\n",
    "\n",
    "    Returns:\n",
    "        float: Valor de la IDF para la palabra dada, calculado como el logaritmo base 10 del número de documentos \n",
    "            con la palabra dividido entre el número total de documentos en el corpus. Si la palabra no aparece en \n",
    "            ningún documento, se retorna 1 para evitar un valor de IDF indefinido.\n",
    "    \"\"\"\n",
    "    # idf = log(numero de docs con la palabra / numero total de docs)\n",
    "    numero_docs_con_palabra = 0\n",
    "    total_docs = 0\n",
    "    for categoria in diccionario_corpus.keys():\n",
    "        for corpus in diccionario_corpus[categoria]:\n",
    "            texto = corpus\n",
    "            palabras = texto.split()\n",
    "            if palabra_diccionario in palabras:  # Si la palabra del diccionario está en el texto\n",
    "                numero_docs_con_palabra += 1  # Aumentamos los documentos con la palabra\n",
    "            total_docs += 1  # Contamos el total de documentos\n",
    "\n",
    "    if numero_docs_con_palabra == 0:  # log(0) no existe, por lo tanto, asignamos idf = 1\n",
    "        idf = 1\n",
    "    else:\n",
    "        idf = math.log10(numero_docs_con_palabra / total_docs)  # Calculamos IDF\n",
    "    return idf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ucB9QTw_LTn"
   },
   "outputs": [],
   "source": [
    "def codificacion_tf_idf(values, diccionario, diccionario_corpus):\n",
    "    \"\"\"\n",
    "    Calcula la codificación TF-IDF para una lista de textos, donde cada texto se representa \n",
    "    mediante un vector de características basado en el TF-IDF de las palabras de un diccionario.\n",
    "\n",
    "    Args:\n",
    "        values (list of str): Lista de textos (corpus) a codificar.\n",
    "        diccionario (list of str): Lista de palabras que conforman el vocabulario para calcular \n",
    "            el TF-IDF.\n",
    "        diccionario_corpus (dict): Diccionario que representa el corpus completo, donde las claves son \n",
    "            categorías y los valores son listas de textos (documentos). Se utiliza para calcular el IDF.\n",
    "\n",
    "    Returns:\n",
    "        list of list of float: Lista de vectores, donde cada sublista representa la codificación TF-IDF \n",
    "            de un texto, calculada para cada palabra del diccionario.\n",
    "    \"\"\"\n",
    "    # Cálculo de tf-idf = (repetición de palabra en un documento / palabras totales del documento) \n",
    "    # / log10(docs con esa palabra / total de documentos)\n",
    "    lista_codificacion = []\n",
    "    for corpus in values:\n",
    "        texto = corpus\n",
    "        # Iteramos sobre las palabras del diccionario para calcular el vector de codificación TF-IDF\n",
    "        vector = [calculo_tf(texto, palabra_diccionario.lower()) / calculo_idf(diccionario_corpus, palabra_diccionario.lower()) for palabra_diccionario in diccionario]\n",
    "        lista_codificacion.append(vector)  # Añadimos el vector de codificación a la lista\n",
    "        vector = []  # Limpiamos el vector para la próxima iteración\n",
    "    return lista_codificacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de palabras para la codificación\n",
    "diccionario = (\"Equipo\", \"Final\", \"Victoria\", \"Retiro\", \"Estrella\", \"Contrato\",\n",
    "               \"Baloncesto\", \"Lesión\", \"Campeón\", \"Competencia\", \"Presidente\",\n",
    "               \"Corrupción\", \"Escándalo\", \"Conflictos\", \"Legislación\", \"Partidos\",\n",
    "               \"Reforma\", \"Oposición\", \"Campaña\", \"Democracia\", \"Película\", \"Estreno\",\n",
    "               \"Pop\", \"Álbum\", \"Festival\", \"Cine\", \"Estrella\", \"Canciones\", \"Actuaciones\",\n",
    "               \"Celebración\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWnQUlyg_P6v"
   },
   "outputs": [],
   "source": [
    "diccionario_corpus_codificacion = {} #creamos un nuevo diccionario donde se guardaran los corpus codificados (con mismas claves)\n",
    "for categoria,values in diccionario_corpus.items():\n",
    "  if categoria in diccionario_corpus_codificacion.keys():\n",
    "    diccionario_corpus_codificacion.append(codificacion_tf_idf(values,diccionario,diccionario_corpus))\n",
    "  else:\n",
    "    diccionario_corpus_codificacion[categoria] = codificacion_tf_idf(values,diccionario,diccionario_corpus) #en cada categoria se agregara al codificacion de su respectivo corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQBdjtu8I-na",
    "outputId": "0048b3a5-f554-4b8e-8109-525679b28a85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte : [[-0.057274622325644176, -0.0639054074502846, -0.0319527037251423, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0], [-0.0, -0.0, -0.0, -0.03894233966480209, -0.03894233966480209, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.03894233966480209, -0.0, -0.0, 0.0], [-0.16609640474436813, -0.0, -0.0, -0.0, -0.0, -0.030887613600970892, -0.030887613600970892, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0], [-0.05357948540140907, -0.0, -0.0, -0.04145474867543447, -0.0, -0.0, -0.0, -0.059782477937363014, -0.029891238968681507, -0.029891238968681507, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0]]\n",
      "politica : [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.026475097372260763, -0.026475097372260763, -0.05295019474452153, -0.026475097372260763, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0], [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.02375970276997761, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0], [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.033093871715325955, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0], [-0.0, -0.0, -0.0, -0.0, -0.0, -0.027253776706739022, -0.0, -0.0, -0.0, -0.0, -0.0, -0.027253776706739022, -0.027253776706739022, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0], [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.02504401102781424, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0]]\n",
      "entretenimiento : [[-0.0, -0.02375970276997761, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.04751940553995522, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.02375970276997761, 0.0], [-0.0, -0.0, -0.0, -0.0, -0.03295121048560176, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.02375970276997761, -0.04751940553995522, -0.0, -0.0, -0.03295121048560176, -0.02375970276997761, -0.0, 0.0], [-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.02260069287875919, 0.0, -0.0, -0.0, -0.06780207863627756, -0.04520138575751838, -0.0, -0.0, -0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "for categoria,corpus in diccionario_corpus_codificacion.items(): #Usamos este metodo .items() para iterar segun categorias y sus respectivos corpus para ver si todo esta bien guardado\n",
    "  print(f\"{categoria} : {corpus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsK7SQ7SJiSr"
   },
   "source": [
    "# 3. Calculo similitudes\n",
    "## 3.1 Similitud del Coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhuVAKzHJgFt"
   },
   "outputs": [],
   "source": [
    "def coseno(query_codificado, corpus_codificado):\n",
    "    \"\"\"\n",
    "    Calcula la similitud coseno entre dos vectores codificados.\n",
    "\n",
    "    La similitud coseno se calcula como el producto escalar de los vectores dividido entre el producto de \n",
    "    sus longitudes (módulos). La fórmula es: similitud_coseno = (a * b) / (|a| * |b|), donde:\n",
    "        - a es el vector codificado del corpus.\n",
    "        - b es el vector codificado de la consulta (query).\n",
    "        - |a| es la magnitud del vector a, calculada como la raíz cuadrada de la sumatoria de los cuadrados de sus elementos.\n",
    "        - |b| es la magnitud del vector b, calculada de la misma manera.\n",
    "\n",
    "    Args:\n",
    "        query_codificado (list of float): Vector codificado que representa la consulta (query).\n",
    "        corpus_codificado (list of float): Vector codificado que representa un documento del corpus.\n",
    "\n",
    "    Returns:\n",
    "        float: Valor de la similitud coseno entre los dos vectores. Si alguno de los vectores tiene magnitud cero, \n",
    "            se retorna 0.\n",
    "    \"\"\"\n",
    "    sumatoria_a_cuadrado = 0\n",
    "    sumatoria_b_cuadrado = 0\n",
    "    sumatoria_a_por_b = 0\n",
    "\n",
    "    # Calculamos la sumatoria de los cuadrados de los elementos de ambos vectores\n",
    "    for a in corpus_codificado:\n",
    "        sumatoria_a_cuadrado += float(a) ** 2\n",
    "\n",
    "    for b in query_codificado:\n",
    "        sumatoria_b_cuadrado += float(b) ** 2\n",
    "\n",
    "    # Calculamos el producto escalar entre los dos vectores\n",
    "    for a, b in zip(corpus_codificado, query_codificado):\n",
    "        sumatoria_a_por_b += float(a) * float(b)\n",
    "\n",
    "    # Si la magnitud de alguno de los vectores es 0, la similitud coseno es 0\n",
    "    if sumatoria_a_cuadrado == 0 or sumatoria_b_cuadrado == 0:\n",
    "        similitud_coseno = 0\n",
    "    else:\n",
    "        similitud_coseno = sumatoria_a_por_b / (math.sqrt(sumatoria_a_cuadrado) * math.sqrt(sumatoria_b_cuadrado))\n",
    "\n",
    "    return similitud_coseno\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcqB2nb5KMeX"
   },
   "source": [
    "## 3.2 Similitud Euclidea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXMgAPadKPhh"
   },
   "outputs": [],
   "source": [
    "def euclides(query_codificado, corpus_codificado):\n",
    "    \"\"\"\n",
    "    Calcula la distancia euclidiana entre dos vectores codificados.\n",
    "\n",
    "    La distancia euclidiana se calcula utilizando la fórmula:\n",
    "        distancia_euclidea = sqrt(sumatoria((b - a)^2)), donde:\n",
    "            - a es el vector codificado de la consulta (query).\n",
    "            - b es el vector codificado del documento del corpus.\n",
    "\n",
    "    Args:\n",
    "        query_codificado (list of float): Vector codificado que representa la consulta (query).\n",
    "        corpus_codificado (list of float): Vector codificado que representa un documento del corpus.\n",
    "\n",
    "    Returns:\n",
    "        float: Distancia euclidiana entre los dos vectores. Un valor más bajo indica mayor similitud.\n",
    "    \"\"\"\n",
    "    sumatoria_b_menos_a_cuadrado = 0\n",
    "    for a, b in zip(corpus_codificado, query_codificado):\n",
    "        sumatoria_b_menos_a_cuadrado += ((float(b) - float(a)) ** 2)\n",
    "    euclides = math.sqrt(sumatoria_b_menos_a_cuadrado)\n",
    "    return euclides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rX_SNB3dALB"
   },
   "source": [
    "## 3.3 Similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M22ggKJjdCQs"
   },
   "outputs": [],
   "source": [
    "def similitud(query_codificado, diccionario_corpus_codificacion, num):\n",
    "    \"\"\"\n",
    "    Calcula la categoría más similar a una consulta (query) codificada utilizando una métrica de similitud.\n",
    "\n",
    "    La función utiliza dos métricas de similitud para comparar un vector de consulta codificado con los vectores \n",
    "    codificados en un corpus: \n",
    "    - Similitud del coseno (cuando `num` es 1).\n",
    "    - Distancia euclidiana (cuando `num` es 2).\n",
    "\n",
    "    Args:\n",
    "        query_codificado (list of float): Vector codificado que representa la consulta (query).\n",
    "        diccionario_corpus_codificacion (dict): Diccionario donde las claves son categorías y los valores son \n",
    "            listas de vectores codificados que representan los documentos de cada categoría.\n",
    "        num (int): Parámetro que indica qué métrica de similitud usar:\n",
    "            - 1 para similitud coseno.\n",
    "            - 2 para distancia euclidiana.\n",
    "\n",
    "    Returns:\n",
    "        str: La categoría del vector más similar al query, basado en la métrica de similitud especificada.\n",
    "            Para la similitud coseno, se retorna la categoría con el valor más alto de similitud.\n",
    "            Para la distancia euclidiana, se retorna la categoría con el valor más bajo de distancia.\n",
    "\n",
    "    Notes:\n",
    "        - Si `num` es 1, la función busca el vector con la mayor similitud coseno.\n",
    "        - Si `num` es 2, la función busca el vector con la menor distancia euclidiana.\n",
    "    \"\"\"\n",
    "    # Inicialización de la variable que almacenará la mayor similitud encontrada.\n",
    "    if num == 1:\n",
    "        mayor_similitud = -1000  # Valor inicial bajo para asegurar que cualquier similitud real será mayor.\n",
    "    elif num == 2:\n",
    "        mayor_similitud = float('inf')  # Valor inicial alto para asegurar que cualquier distancia real será menor.\n",
    "\n",
    "    # Variable para almacenar la categoría del vector más similar.\n",
    "    categoria_query = \"\"\n",
    "\n",
    "    # Iteramos sobre cada categoría y sus vectores codificados en el diccionario.\n",
    "    for categoria, corpus_codificados in diccionario_corpus_codificacion.items():\n",
    "        # Iteramos sobre cada vector dentro de una categoría específica.\n",
    "        for vector in corpus_codificados:\n",
    "            # Calculamos la similitud del coseno si num es 1.\n",
    "            if num == 1:\n",
    "                similitud_actual = coseno(query_codificado, vector)\n",
    "            # Calculamos la distancia euclídea si num es 2.\n",
    "            elif num == 2:\n",
    "                similitud_actual = euclides(query_codificado, vector)\n",
    "\n",
    "            # Actualizamos la mayor similitud y la categoría correspondiente.\n",
    "            # Para la similitud del coseno, buscamos valores más altos.\n",
    "            # Para la distancia euclídea, buscamos valores más bajos.\n",
    "            if (num == 1 and similitud_actual > mayor_similitud) or (num == 2 and similitud_actual < mayor_similitud):\n",
    "                mayor_similitud = similitud_actual\n",
    "                categoria_query = categoria\n",
    "\n",
    "    # Devolvemos la categoría del vector más similar.\n",
    "    return categoria_query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCzHfFf3KXTC"
   },
   "source": [
    "# 4. Clasificar\n",
    "# 4.1 Carga de querys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjU306qPKbzB"
   },
   "outputs": [],
   "source": [
    "PATH = \"querys/\"\n",
    "contenido = glob.glob(PATH+\"*.txt\")\n",
    "diccionario_querys = {}  # Inicializa como una lista vacía\n",
    "for clave,archivo in enumerate(contenido):\n",
    "    with open(archivo, \"r\") as query_txt:\n",
    "        query = query_txt.read()\n",
    "    if clave in diccionario_querys.keys():\n",
    "      diccionario_querys[clave].append(query)\n",
    "    else:\n",
    "      diccionario_querys[clave] = query #en este caso cada query tendra una clave (llave) unica, ya que no sabemos a categoria estan asociados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhP3fDAMNriU"
   },
   "source": [
    "## 4.1.1 Limpiamos Querys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZ9kds7cR0Aw"
   },
   "outputs": [],
   "source": [
    "def limpieza_query(query, simbolos, stop_words):\n",
    "    \"\"\"\n",
    "    Limpia una consulta (query) eliminando símbolos y palabras de parada (stop words).\n",
    "\n",
    "    La función realiza dos pasos de limpieza en la consulta:\n",
    "    1. Elimina los símbolos no deseados de la consulta utilizando una lista de símbolos proporcionada.\n",
    "    2. Elimina las palabras de parada (stop words) de la consulta, ignorando mayúsculas y minúsculas.\n",
    "\n",
    "    Args:\n",
    "        query (str): Texto de la consulta a limpiar.\n",
    "        simbolos (list of str): Lista de símbolos que deben eliminarse del texto.\n",
    "        stop_words (list of str): Lista de palabras de parada que deben eliminarse del texto.\n",
    "\n",
    "    Returns:\n",
    "        str: La consulta limpia, con los símbolos y las palabras de parada eliminadas, y las palabras en minúsculas.\n",
    "\n",
    "    Notes:\n",
    "        - Los símbolos se reemplazan por un espacio vacío.\n",
    "        - Las palabras se convierten a minúsculas antes de comparar con las stop words.\n",
    "    \"\"\"\n",
    "    texto = query\n",
    "    # Eliminamos los símbolos no deseados\n",
    "    for simbolo in simbolos:\n",
    "        texto = texto.replace(simbolo, \"\")\n",
    "    # Filtramos las palabras que no están en stop words\n",
    "    palabras = texto.split()\n",
    "    palabras_filtradas = [palabra.lower() for palabra in palabras if palabra.lower() not in stop_words]\n",
    "    # Unimos las palabras filtradas para obtener el texto limpio\n",
    "    texto_filtrado = \" \".join(palabras_filtradas)\n",
    "    return texto_filtrado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCMENuekSe2E"
   },
   "outputs": [],
   "source": [
    "for clave, query in diccionario_querys.items():\n",
    "  diccionario_querys[clave] = limpieza_query(query, simbolos_redundantes, stop_words_espanol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7cOSILvYUGO",
    "outputId": "a9ff3856-9f1b-46a2-c703-d8010b27d9ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clave: 0, Valor: equipo nacional fútbol logra histórica victoria final campeonato mundial asegurando trofeo codiciado deporte después enfrentar rivales formidables valentía determinación llevaron triunfo generando gran orgullo celebración país victoria resultado años trabajo dedicación equipo espera inspirar futuras generaciones deportistas\n",
      "Clave: 1, Valor: nuevo gobierno electo presenta agenda legislativa próximo año destacando prioridades crecimiento económico empleo salud educación medio ambiente espera diálogo constructivo partidos políticos abordar desafíos nacionales objetivo mejorar calidad vida ciudadanos promover cambio progreso país\n",
      "Clave: 2, Valor: estreno mundial esperada película ciencia ficción orígenes: allá universo dirigida alex west evento lleno anticipación emoción película elogiada efectos visuales actuaciones promete llevar espectadores experiencia cinematográfica precedentes explorando misterios cosmos desafiando límites imaginación\n",
      "Clave: 3, Valor: nueva película ciencia ficción dirigida aclamado director christopher nolan promete ser éxito taquilla verano elenco estelar efectos especiales última generación película transportará espectadores mundo aventura misterio\n",
      "Clave: 4, Valor: festival música grande país punto comenzar alineación impresionante incluye artistas renombre internacional espera miles fanáticos acudan evento disfrutar tres días música vivo entretenimiento\n",
      "Clave: 5, Valor: equipo fútbol nacional avanzado final torneo continental después emocionante serie partidos eliminatorios aficionados emocionados perspectiva ver equipo competir título rivales históricos\n",
      "Clave: 6, Valor: parlamento aprobado ley controvertida genera divisiones sociedad partidos oposición critican medida ataque libertades civiles mientras gobierno defiende necesaria garantizar seguridad nacional\n",
      "Clave: 7, Valor: nuevo gobierno anunciado ambicioso plan reformas abordar desafíos económicos sociales país medidas incluyen inversiones infraestructura programas empleo reformas sistema salud educación\n"
     ]
    }
   ],
   "source": [
    "for clave, valor in diccionario_querys.items():\n",
    "    print(f\"Clave: {clave}, Valor: {valor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LNOxbdrLypy"
   },
   "source": [
    "## 4.2 Codificacion de querys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5BNAYGkUM08"
   },
   "outputs": [],
   "source": [
    "def calculo_idf_query(diccionario_querys, palabra_diccionario):\n",
    "    \"\"\"\n",
    "    Calcula el valor de IDF (Inverse Document Frequency) para una palabra específica dentro de un conjunto de consultas.\n",
    "\n",
    "    El IDF se calcula usando la siguiente fórmula:\n",
    "    IDF = log10(numero de consultas que contienen la palabra / número total de consultas).\n",
    "    \n",
    "    Si una palabra no aparece en ninguna consulta, el valor de IDF es 1.\n",
    "    Si el valor de IDF es cero debido a la rareza de la palabra, también se ajusta a 1 para evitar errores en el cálculo posterior.\n",
    "\n",
    "    Args:\n",
    "        diccionario_querys (dict): Diccionario donde las claves son identificadores de consultas y los valores son las consultas (strings) completas.\n",
    "        palabra_diccionario (str): Palabra para la cual se desea calcular el valor IDF.\n",
    "\n",
    "    Returns:\n",
    "        float: Valor de IDF para la palabra dada, que mide su importancia inversa en el conjunto de consultas.\n",
    "\n",
    "    Notes:\n",
    "        - Si la palabra no aparece en ninguna consulta, el IDF es 1 por defecto.\n",
    "        - Si el valor de IDF calculado es 0, también se ajusta a 1 para evitar divisiones por cero o problemas con valores muy pequeños.\n",
    "    \"\"\"\n",
    "    numero_docs_con_palabra = 0\n",
    "    total_docs = 0\n",
    "\n",
    "    for clave in diccionario_querys.keys():\n",
    "        texto = diccionario_querys[clave]\n",
    "        palabras = texto.split()\n",
    "        if palabra_diccionario in palabras:\n",
    "            numero_docs_con_palabra += 1\n",
    "        total_docs += 1\n",
    "\n",
    "    if numero_docs_con_palabra == 0:\n",
    "        idf = 1\n",
    "    else:\n",
    "        idf = math.log10(numero_docs_con_palabra / total_docs)\n",
    "        if idf == 0:  # Prevención de IDF igual a 0 para evitar problemas de cálculo posteriores\n",
    "            idf = 1\n",
    "\n",
    "    return idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5NFNN_kL2ET"
   },
   "outputs": [],
   "source": [
    "def codificacion_tf_idf_querys(query, diccionario, diccionario_querys):\n",
    "    \"\"\"\n",
    "    Calcula la codificación TF-IDF para una consulta (query) usando un diccionario de términos y un diccionario de consultas.\n",
    "\n",
    "    La función calcula el vector TF-IDF para una consulta específica, donde:\n",
    "    - TF (Term Frequency) se calcula como la frecuencia de una palabra en el documento (consulta) dividida entre el total de palabras en el documento.\n",
    "    - IDF (Inverse Document Frequency) se calcula utilizando el diccionario de todas las consultas, en lugar de un corpus completo.\n",
    "\n",
    "    Args:\n",
    "        query (str): Texto de la consulta que se desea codificar.\n",
    "        diccionario (list of str): Lista de palabras del diccionario que se utilizarán para la codificación.\n",
    "        diccionario_querys (dict): Diccionario que contiene las consultas previas y su respectiva codificación, \n",
    "            utilizado para calcular el IDF de cada palabra.\n",
    "\n",
    "    Returns:\n",
    "        list of float: Vector de codificación TF-IDF para la consulta dada, donde cada valor en el vector \n",
    "            representa el peso TF-IDF de una palabra del diccionario en la consulta.\n",
    "\n",
    "    Notes:\n",
    "        - La función asume que las palabras en el diccionario están en minúsculas para evitar discrepancias por mayúsculas.\n",
    "        - Para cada palabra en el diccionario, se calcula su TF y IDF, y luego se realiza la codificación TF-IDF.\n",
    "    \"\"\"\n",
    "    texto = query\n",
    "    vector = [calculo_tf(texto, palabra_diccionario.lower()) / calculo_idf_query(diccionario_querys, palabra_diccionario.lower()) for palabra_diccionario in diccionario]\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPmboDckWvp9"
   },
   "outputs": [],
   "source": [
    "diccionario_querys_codificacion = {}\n",
    "for clave,query in diccionario_querys.items():\n",
    "  if clave in diccionario_corpus_codificacion.keys():\n",
    "    pass #Como clave es unica sabemos que nunca entrara aqui por lo cual es omitible\n",
    "  else:\n",
    "    diccionario_querys_codificacion[clave] = codificacion_tf_idf_querys(query,diccionario, diccionario_querys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KngBueGTa4Op",
    "outputId": "fdfe3913-ad8f-4c18-9fcb-dd790eb48c11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08978184040236115, -0.04489092020118057, -0.05985456026824077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, -0.0, 0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.029927280134120385]\n",
      "[-0.0, -0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.06904676911140561, 0.0, -0.0, 0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.0]\n",
      "[-0.0, -0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, -0.0, 0.0, 0.0, -0.10066448772385947, -0.03355482924128649, 0.0, 0.0, -0.0, 0.030303030303030304, 0.0, 0.0, -0.03355482924128649, -0.0]\n",
      "[-0.0, -0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, -0.0, 0.0, 0.0, -0.1277664651879755, -0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.0]\n",
      "[-0.0, -0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, -0.0, 0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.04814388543315018, 0.0, 0.0, 0.0, -0.0, -0.0]\n",
      "[-0.15818705213749343, -0.07909352606874671, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.11179000713275195, 0.0, -0.0, 0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.0]\n",
      "[-0.0, -0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.11179000713275195, 0.0, -0.05272901737916448, 0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.0]\n",
      "[-0.0, -0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.09523809523809523, -0.0, 0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.0]\n"
     ]
    }
   ],
   "source": [
    "for clave in diccionario_querys_codificacion.keys(): #Comprobacion de todo en orden\n",
    "  print(diccionario_querys_codificacion[clave])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpZxaR3ebsoD"
   },
   "source": [
    "## 4.3 Clasificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVePOc_rboAe"
   },
   "outputs": [],
   "source": [
    "def clasificar(query_codificado, diccionario_corpus_codificacion, num):\n",
    "    \"\"\"\n",
    "    Clasifica una consulta codificada (query) en la categoría más similar dentro de un diccionario de corpus codificados.\n",
    "\n",
    "    La función utiliza una medida de similitud (coseno o euclídea) para comparar el vector codificado de la consulta con los vectores codificados en el diccionario.\n",
    "    Dependiendo del valor de `num`, se utiliza la similitud del coseno (si `num` es 1) o la distancia euclídea (si `num` es 2) para determinar la categoría más similar.\n",
    "\n",
    "    Args:\n",
    "        query_codificado (list of float): El vector codificado de la consulta.\n",
    "        diccionario_corpus_codificacion (dict): Diccionario donde las claves son las categorías y los valores son listas de vectores codificados del corpus.\n",
    "        num (int): Determina el tipo de similitud a usar:\n",
    "            - 1 para similitud del coseno.\n",
    "            - 2 para distancia euclídea.\n",
    "\n",
    "    Returns:\n",
    "        str: La categoría del corpus más similar a la consulta según la similitud calculada.\n",
    "\n",
    "    Notes:\n",
    "        - Si `num` es 1, se utiliza la similitud del coseno para determinar la categoría más similar.\n",
    "        - Si `num` es 2, se utiliza la distancia euclídea para determinar la categoría más similar.\n",
    "    \"\"\"\n",
    "    categoria_query = similitud(query_codificado, diccionario_corpus_codificacion, num)\n",
    "    return categoria_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zx07d8-_dlsn",
    "outputId": "e98dba4d-2f60-4057-ff90-29e4ac5e297d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando similitud del coseno, Query 0 pertence a deporte\n",
      "Usando similitud del coseno, Query 1 pertence a politica\n",
      "Usando similitud del coseno, Query 2 pertence a entretenimiento\n",
      "Usando similitud del coseno, Query 3 pertence a entretenimiento\n",
      "Usando similitud del coseno, Query 4 pertence a entretenimiento\n",
      "Usando similitud del coseno, Query 5 pertence a deporte\n",
      "Usando similitud del coseno, Query 6 pertence a politica\n",
      "Usando similitud del coseno, Query 7 pertence a deporte\n"
     ]
    }
   ],
   "source": [
    "for clave,query_codificado in diccionario_querys_codificacion.items():\n",
    "  print(f\"Usando similitud del coseno, Query {clave} pertence a {clasificar(query_codificado,diccionario_corpus_codificacion,1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSKnKG0LeQbT",
    "outputId": "98d48979-e518-468b-c293-95e3b0d46f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando similitud euclidea, Query 0 pertence a deporte\n",
      "Usando similitud euclidea, Query 1 pertence a politica\n",
      "Usando similitud euclidea, Query 2 pertence a entretenimiento\n",
      "Usando similitud euclidea, Query 3 pertence a entretenimiento\n",
      "Usando similitud euclidea, Query 4 pertence a politica\n",
      "Usando similitud euclidea, Query 5 pertence a deporte\n",
      "Usando similitud euclidea, Query 6 pertence a politica\n",
      "Usando similitud euclidea, Query 7 pertence a politica\n"
     ]
    }
   ],
   "source": [
    "for clave,query_codificado in diccionario_querys_codificacion.items():\n",
    "  print(f\"Usando similitud euclidea, Query {clave} pertence a {clasificar(query_codificado,diccionario_corpus_codificacion,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FccLwc1vYqZ"
   },
   "source": [
    "# Reporte\n",
    "\n",
    "## 1. Resultados\n",
    "\n",
    "Usar tablas y gráficos para explicar los resultados obtenidos.\n",
    "\n",
    "| **Modelo** | **Función de Similitud** | **Accuracy** (Tasa de acierto) |\n",
    "|---|---|---|\n",
    "| 01 | Coseno | 100% |\n",
    "| 02 | Euclídea | 75% |\n",
    "\n",
    "\n",
    "### Modelos\n",
    "\n",
    "*   01: Similitud del coseno. Explicación\\\n",
    "Similitud del Coseno y TF-IDF: El concepto básico detrás de la similitud del coseno es medir la similitud entre dos vectores en un espacio multidimensional. Cada documento del corpus y cada query (consulta) se representan como vectores en un espacio vectorial, donde cada dimensión representa una palabra del diccionario. Estos vectores están codificados utilizando la técnica TF-IDF (Term Frequency-Inverse Document Frequency), que asigna pesos a las palabras basándose en su frecuencia en el documento y en cuántos documentos la contienen.\n",
    "\n",
    "* Cálculo de la similitud del coseno con TF-IDF:\\\n",
    "Se define la función coseno que toma dos argumentos: query_codificado y corpus_codificado, que representan los vectores de características de la consulta y el corpus, respectivamente.\\\n",
    "Se inicializan tres variables (sumatoria_a_cuadrado, sumatoria_b_cuadrado, sumatoria_a_por_b) para calcular diferentes partes de la fórmula de similitud coseno.\\\n",
    "Se itera sobre los elementos del vector corpus_codificado y calcula la suma de los cuadrados de estos elementos, almacenando el resultado en sumatoria_a_cuadrado.\\\n",
    "Se itera sobre los elementos del vector query_codificado y calcula la suma de los cuadrados de estos elementos, almacenando el resultado en sumatoria_b_cuadrado.\\\n",
    "Se utiliza la función zip para iterar simultáneamente sobre los elementos de corpus_codificado y query_codificado. Calcula el producto punto entre los elementos correspondientes de ambos vectores y acumula el resultado en sumatoria_a_por_b.\\\n",
    "Se comprueba si alguno de los vectores tiene una longitud nula (es decir, si alguno de los vectores es un vector nulo) para evitar divisiones por cero en el cálculo de la similitud coseno.\\\n",
    "Se calcula la similitud coseno dividiendo la suma acumulada de productos punto (sumatoria_a_por_b) entre la raíz cuadrada del producto de las sumas de cuadrados de los dos vectores.\n",
    "\n",
    "\n",
    "\n",
    "*   02: Similitud Euclídea. Explicación\\\n",
    "Función Euclidiana: La función euclides calcula la similitud euclidiana entre el vector del query y un vector del corpus codificado en TF-IDF. La similitud euclidiana mide la distancia entre dos puntos en un espacio n-dimensional utilizando la fórmula de la distancia euclidiana.\n",
    "\n",
    "* Cálculo de la Similitud Euclidiana:\\\n",
    "Se define la función euclides que toma dos argumentos: query_codificado y corpus_codificado, que representan los vectores de características del query y el corpus, respectivamente.\\\n",
    "Se inicializa una variable sumatoria_b_menos_a_cuadrado para acumular la suma de los cuadrados de las diferencias entre los elementos correspondientes de query_codificado y corpus_codificado.\\\n",
    "Se utiliza la función zip para iterar simultáneamente sobre los elementos de corpus_codificado y query_codificado. Para cada par de elementos, calcula la diferencia entre los elementos correspondientes, eleva al cuadrado esta diferencia y acumula el resultado en sumatoria_b_menos_a_cuadrado.\\\n",
    "Finalmente, se calcula la raíz cuadrada de la suma acumulada (sumatoria_b_menos_a_cuadrado) para obtener la distancia euclidiana."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
